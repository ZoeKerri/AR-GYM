import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# ğŸŸ¢ BÆ°á»›c 1: Äá»c dá»¯ liá»‡u tá»« file CSV
df = pd.read_csv("data_training.csv")

# ğŸŸ¢ BÆ°á»›c 2: TÃ¡ch dá»¯ liá»‡u vÃ  nhÃ£n (X, y)
X = df.drop(columns=["label"]).values
y = df["label"].values

# ğŸŸ¢ BÆ°á»›c 3: Chia táº­p train/test (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸŸ¢ BÆ°á»›c 4: Chuyá»ƒn nhÃ£n tá»« chá»¯ sang sá»‘
encoder = LabelEncoder()
y_train_encoded = encoder.fit_transform(y_train)
y_test_encoded = encoder.transform(y_test)

# ğŸŸ¢ BÆ°á»›c 5: XÃ¢y dá»±ng mÃ´ hÃ¬nh CNN
model = keras.Sequential([
    layers.Dense(128, activation="relu", input_shape=(X_train.shape[1],)),  
    layers.Dense(64, activation="relu"),
    layers.Dense(len(set(y_train_encoded)), activation="softmax")  
])

# Compile mÃ´ hÃ¬nh
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# ğŸŸ¢ BÆ°á»›c 6: Huáº¥n luyá»‡n mÃ´ hÃ¬nh
model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_data=(X_test, y_test_encoded))

# ğŸŸ¢ BÆ°á»›c 7: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
loss, acc = model.evaluate(X_test, y_test_encoded)
print(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {acc * 100:.2f}%")

# ğŸŸ¢ BÆ°á»›c 8: Dá»± Ä‘oÃ¡n vá»›i dá»¯ liá»‡u má»›i
sample_index = 5
new_sample = X_test[sample_index].reshape(1, -1)
predicted_label = model.predict(new_sample)
predicted_class = encoder.inverse_transform([np.argmax(predicted_label)])

print(f"ğŸ“ BÃ i táº­p dá»± Ä‘oÃ¡n: {predicted_class[0]}")
print(f"âœ… BÃ i táº­p thá»±c táº¿: {encoder.inverse_transform([y_test_encoded[sample_index]])[0]}")

# ğŸŸ¢ BÆ°á»›c 9: LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ train
model.save("exercise_cnn_model.h5")
print("ğŸ’¾ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u thÃ nh cÃ´ng!")
